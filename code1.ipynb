{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import timm  # Import timm for NASNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Custom dataset class to load images from directories\n",
    "class GrapeLeafDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Load dataset from Kaggle directory\n",
    "data_dir = \"Grapevine_Leaves_Image_Dataset\"\n",
    "classes = sorted(os.listdir(data_dir))\n",
    "\n",
    "# Extract image paths and labels\n",
    "image_paths, labels = [], []\n",
    "for class_idx, class_name in enumerate(classes):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    for img_file in os.listdir(class_dir):\n",
    "        image_paths.append(os.path.join(class_dir, img_file))\n",
    "        labels.append(class_idx)\n",
    "\n",
    "# Split into train and test sets\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "# Create dataset objects\n",
    "train_dataset = GrapeLeafDataset(train_paths, train_labels, transform=transform)\n",
    "test_dataset = GrapeLeafDataset(test_paths, test_labels, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom CNN Model\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(architecture, num_classes):\n",
    "    architecture = architecture.lower()\n",
    "    \n",
    "    if architecture == \"customcnn\":  # âœ… Add CustomCNN model\n",
    "        model = CustomCNN(num_classes)\n",
    "    \n",
    "    elif architecture == \"resnet\":\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "    elif architecture == \"efficientnet\":\n",
    "        model = models.efficientnet_b0(pretrained=True)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "\n",
    "    elif architecture == \"vgg\":\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "\n",
    "    elif architecture == \"mobilenet\":\n",
    "        model = models.mobilenet_v3_large(pretrained=True)\n",
    "        model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
    "\n",
    "    elif architecture == \"densenet\":\n",
    "        model = models.densenet121(pretrained=True)\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "\n",
    "    elif architecture == \"nasnet\":\n",
    "        model = timm.create_model(\"nasnetalarge\", pretrained=True)\n",
    "        if hasattr(model, \"classifier\"):\n",
    "            model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "        elif hasattr(model, \"last_linear\"):\n",
    "            model.last_linear = nn.Linear(model.last_linear.in_features, num_classes)\n",
    "        else:\n",
    "            raise AttributeError(\"Could not find the classification layer in NASNetALarge.\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown architecture: {architecture}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Settings\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = len(classes)\n",
    "num_epochs = 5\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "models_list = {\n",
    "    \"CustomCNN\": CustomCNN(num_classes).to(device),\n",
    "    \"ResNet\": load_model(\"resnet\", num_classes).to(device),\n",
    "    \"EfficientNet\": load_model(\"efficientnet\", num_classes).to(device),\n",
    "    \"VGG\": load_model(\"vgg\", num_classes).to(device),\n",
    "    \"MobileNet\": load_model(\"mobilenet\", num_classes).to(device),\n",
    "    \"DenseNet\": load_model(\"densenet\", num_classes).to(device),\n",
    "    \"NASNet\": load_model(\"nasnet\", num_classes).to(device)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate model\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    correct, total, loss_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_total += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return loss_total / len(data_loader), 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CustomCNN...\n",
      "\n",
      "Epoch [1/5] Train Loss: 1.6164, Train Acc: 23.00% | Val Loss: 1.6072, Val Acc: 32.00%\n",
      "Epoch [2/5] Train Loss: 1.5728, Train Acc: 28.25% | Val Loss: 1.5696, Val Acc: 25.00%\n",
      "Epoch [3/5] Train Loss: 1.3981, Train Acc: 41.25% | Val Loss: 1.4184, Val Acc: 38.00%\n",
      "Epoch [4/5] Train Loss: 1.1025, Train Acc: 57.75% | Val Loss: 1.4384, Val Acc: 39.00%\n",
      "Epoch [5/5] Train Loss: 0.7839, Train Acc: 69.50% | Val Loss: 1.4060, Val Acc: 46.00%\n",
      "\n",
      "Training ResNet...\n",
      "\n",
      "Epoch [1/5] Train Loss: 1.5845, Train Acc: 41.75% | Val Loss: 13.5240, Val Acc: 22.00%\n",
      "Epoch [2/5] Train Loss: 1.0425, Train Acc: 62.00% | Val Loss: 14.4105, Val Acc: 31.00%\n",
      "Epoch [3/5] Train Loss: 0.6395, Train Acc: 75.75% | Val Loss: 2.2566, Val Acc: 55.00%\n",
      "Epoch [4/5] Train Loss: 0.5994, Train Acc: 77.25% | Val Loss: 4.0221, Val Acc: 27.00%\n",
      "Epoch [5/5] Train Loss: 0.4117, Train Acc: 85.75% | Val Loss: 1.4332, Val Acc: 62.00%\n",
      "\n",
      "Training EfficientNet...\n",
      "\n",
      "Epoch [1/5] Train Loss: 1.0465, Train Acc: 57.00% | Val Loss: 1.8541, Val Acc: 39.00%\n",
      "Epoch [2/5] Train Loss: 0.4987, Train Acc: 84.50% | Val Loss: 0.8532, Val Acc: 77.00%\n",
      "Epoch [3/5] Train Loss: 0.3379, Train Acc: 89.25% | Val Loss: 0.6281, Val Acc: 82.00%\n",
      "Epoch [4/5] Train Loss: 0.3796, Train Acc: 88.25% | Val Loss: 0.3953, Val Acc: 88.00%\n",
      "Epoch [5/5] Train Loss: 0.2471, Train Acc: 93.00% | Val Loss: 0.3081, Val Acc: 94.00%\n",
      "\n",
      "Training VGG...\n",
      "\n",
      "Epoch [1/5] Train Loss: 1.9021, Train Acc: 21.50% | Val Loss: 1.6082, Val Acc: 27.00%\n",
      "Epoch [2/5] Train Loss: 1.6400, Train Acc: 19.75% | Val Loss: 1.6198, Val Acc: 20.00%\n",
      "Epoch [3/5] Train Loss: 1.6445, Train Acc: 15.50% | Val Loss: 1.6473, Val Acc: 20.00%\n",
      "Epoch [4/5] Train Loss: 1.6353, Train Acc: 17.00% | Val Loss: 1.6294, Val Acc: 20.00%\n",
      "Epoch [5/5] Train Loss: 1.6306, Train Acc: 16.50% | Val Loss: 1.6226, Val Acc: 20.00%\n",
      "\n",
      "Training MobileNet...\n",
      "\n",
      "Epoch [1/5] Train Loss: 0.9987, Train Acc: 63.00% | Val Loss: 1.1267, Val Acc: 54.00%\n",
      "Epoch [2/5] Train Loss: 0.4035, Train Acc: 89.25% | Val Loss: 2.5454, Val Acc: 43.00%\n",
      "Epoch [3/5] Train Loss: 0.3366, Train Acc: 89.00% | Val Loss: 2.7085, Val Acc: 40.00%\n",
      "Epoch [4/5] Train Loss: 0.1444, Train Acc: 94.25% | Val Loss: 4.7059, Val Acc: 36.00%\n",
      "Epoch [5/5] Train Loss: 0.2051, Train Acc: 92.75% | Val Loss: 8.2819, Val Acc: 32.00%\n",
      "\n",
      "Training DenseNet...\n",
      "\n",
      "Epoch [1/5] Train Loss: 0.9525, Train Acc: 64.50% | Val Loss: 8.5506, Val Acc: 21.00%\n",
      "Epoch [2/5] Train Loss: 0.5685, Train Acc: 78.75% | Val Loss: 3.3516, Val Acc: 39.00%\n",
      "Epoch [3/5] Train Loss: 0.3310, Train Acc: 88.75% | Val Loss: 2.9303, Val Acc: 46.00%\n",
      "Epoch [4/5] Train Loss: 0.3188, Train Acc: 88.25% | Val Loss: 1.9298, Val Acc: 64.00%\n",
      "Epoch [5/5] Train Loss: 0.2069, Train Acc: 92.50% | Val Loss: 0.7270, Val Acc: 74.00%\n",
      "\n",
      "Training NASNet...\n",
      "\n",
      "Epoch [1/5] Train Loss: 1.4278, Train Acc: 45.50% | Val Loss: 3.0410, Val Acc: 38.00%\n",
      "Epoch [2/5] Train Loss: 1.1609, Train Acc: 62.00% | Val Loss: 2.3231, Val Acc: 47.00%\n",
      "Epoch [3/5] Train Loss: 0.9708, Train Acc: 66.00% | Val Loss: 1.3720, Val Acc: 62.00%\n",
      "Epoch [4/5] Train Loss: 0.7725, Train Acc: 72.75% | Val Loss: 0.8335, Val Acc: 75.00%\n",
      "Epoch [5/5] Train Loss: 0.5861, Train Acc: 81.50% | Val Loss: 0.6197, Val Acc: 82.00%\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for model_name, model in models_list.items():\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    print(f\"\\nTraining {model_name}...\\n\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "        val_loss, val_acc = evaluate_model(model, test_loader)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    torch.save(model.state_dict(), f\"{model_name}.pth\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_22444\\1723363588.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomCNN Test Accuracy: 0.4600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_22444\\1723363588.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet Test Accuracy: 0.6200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_22444\\1723363588.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet Test Accuracy: 0.9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_22444\\1723363588.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG Test Accuracy: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_22444\\1723363588.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNet Test Accuracy: 0.3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_22444\\1723363588.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet Test Accuracy: 0.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_22444\\1723363588.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASNet Test Accuracy: 0.8200\n",
      "Accuracy plot saved as grapevine_accuracy_plot.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Load trained models and evaluate accuracy\n",
    "model_names = [\"CustomCNN\", \"ResNet\", \"EfficientNet\", \"VGG\", \"MobileNet\", \"DenseNet\", \"NASNet\"]\n",
    "model_accuracies = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    model = load_model(model_name.lower(), num_classes)\n",
    "\n",
    "    model_path = f\"{model_name.lower()}.pth\"\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model checkpoint '{model_path}' not found!\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    model_accuracies[model_name] = accuracy\n",
    "    print(f\"{model_name} Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Plot accuracy chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(model_accuracies.keys(), model_accuracies.values(), color='skyblue')\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Model Performance Comparison on Grapevine Dataset\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot\n",
    "plt.savefig(\"grapevine_accuracy_plot.png\")\n",
    "plt.close()\n",
    "print(\"Accuracy plot saved as grapevine_accuracy_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_22444\\3385842657.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"{model_name}.pth\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Curve saved at roc_curve.png\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "class_names = classes\n",
    "\n",
    "# Load Trained Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_trained_model(model_name):\n",
    "    model = load_model(model_name, num_classes)\n",
    "    model.load_state_dict(torch.load(f\"{model_name}.pth\", map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    return model\n",
    "\n",
    "# ROC Curve Function\n",
    "def plot_roc_curve(model, test_loader, num_classes, class_names):\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            all_preds.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Binarize the labels for ROC curve\n",
    "    all_labels_bin = label_binarize(all_labels, classes=np.arange(num_classes))\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    # Plot ROC curve for each class\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(num_classes):\n",
    "        fpr, tpr, _ = roc_curve(all_labels_bin[:, i], all_preds[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"Class {class_names[i]} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  \n",
    "    plt.title('Multi-Class ROC Curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    roc_image_path = \"roc_curve.png\"\n",
    "    plt.savefig(roc_image_path)\n",
    "    plt.close()\n",
    "\n",
    "    return roc_image_path\n",
    "\n",
    "# Example Usage\n",
    "print(\"Loading model...\")\n",
    "model_name = \"resnet\"  \n",
    "model = load_trained_model(model_name)\n",
    "roc_image_path = plot_roc_curve(model, test_loader, num_classes, class_names)\n",
    "print(\"ROC Curve saved at\", roc_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_22444\\2223757233.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"{model_name}.pth\", map_location=device))  # Fixed model loading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating confusion matrix...\n",
      "Confusion Matrix saved at resnet_confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Load Trained Models\n",
    "def load_trained_model(model_name, num_classes):\n",
    "    model = load_model(model_name, num_classes)  # Pass num_classes dynamically\n",
    "    model.load_state_dict(torch.load(f\"{model_name}.pth\", map_location=device))  # Fixed model loading\n",
    "    model.to(device)\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    return model\n",
    "\n",
    "# Confusion Matrix\n",
    "def generate_confusion_matrix(model_name, model, test_loader, class_names):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # Normalize confusion matrix\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f\"Confusion Matrix for {model_name}\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save confusion matrix plot as PNG\n",
    "    plot_path = f\"{model_name}_confusion_matrix.png\"\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    return plot_path\n",
    "\n",
    "# Choose a model and generate confusion matrix\n",
    "print(\"Loading model...\")\n",
    "model_name = \"resnet\"  # or any model name you want to use\n",
    "model = load_trained_model(model_name, num_classes)  # Pass num_classes dynamically\n",
    "\n",
    "print(\"Generating confusion matrix...\")\n",
    "conf_matrix_image_path = generate_confusion_matrix(model_name, model, test_loader, class_names)\n",
    "\n",
    "print(f\"Confusion Matrix saved at {conf_matrix_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
